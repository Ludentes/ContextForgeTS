# ContextForge TypeScript - Environment Variables
# Copy this to .env.local for local development

# ═══════════════════════════════════════════════════════════════════════════════
# CONVEX
# ═══════════════════════════════════════════════════════════════════════════════
# These are auto-generated when you run `pnpm exec convex dev`
# You don't need to set them manually for local development

# CONVEX_DEPLOYMENT=dev:your-project-name
# VITE_CONVEX_URL=https://your-project.convex.cloud

# ═══════════════════════════════════════════════════════════════════════════════
# OLLAMA (Local LLM)
# ═══════════════════════════════════════════════════════════════════════════════
# Ollama server URL (default: http://localhost:11434)
# OLLAMA_URL=http://localhost:11434

# Default Ollama model (default: llama3.2)
# OLLAMA_MODEL=llama3.2

# ═══════════════════════════════════════════════════════════════════════════════
# CLAUDE CODE (Claude Agent SDK)
# ═══════════════════════════════════════════════════════════════════════════════
# Path to Claude Code CLI executable
# Required for Claude provider - find with: which claude
# CLAUDE_CODE_PATH=/home/user/.local/bin/claude

# ═══════════════════════════════════════════════════════════════════════════════
# OPENROUTER (Multi-model API)
# ═══════════════════════════════════════════════════════════════════════════════
# OpenRouter provides access to Claude, GPT-4, Llama, and many other models
# Get your API key at https://openrouter.ai/keys

# Required for OpenRouter provider
# OPENROUTER_API_KEY=sk-or-v1-...

# Default model (optional, default: anthropic/claude-3.5-sonnet)
# See available models at https://openrouter.ai/models
# OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# Site info for OpenRouter headers (optional)
# OPENROUTER_SITE_URL=http://localhost:5173
# OPENROUTER_SITE_NAME=ContextForge

# ═══════════════════════════════════════════════════════════════════════════════
# LANGFUSE (LLM Observability)
# ═══════════════════════════════════════════════════════════════════════════════
# LangFuse provides tracing for LLM calls - see what prompts are being sent
# Get keys from your LangFuse project settings (self-hosted or cloud.langfuse.com)

# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_BASE_URL=http://localhost:3000

# ═══════════════════════════════════════════════════════════════════════════════
# FUTURE / OPTIONAL
# ═══════════════════════════════════════════════════════════════════════════════
# OpenAI API key (not currently used - reserved for future)
# OPENAI_API_KEY=sk-...

# Anthropic API key (not currently used - we use Claude Code CLI instead)
# ANTHROPIC_API_KEY=sk-ant-...
